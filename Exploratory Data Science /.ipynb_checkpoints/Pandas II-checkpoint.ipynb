{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Data\n",
    "in many cases you have multiple data sets you would like to join. Among the scenarios you will encounter this are:\n",
    "1. multiple sources of data regarding your data points e.g., you start an ad campaign for which you have internal parameters (cost, targeted audience, etc.,) and external results (response rate, convergence rate, etc.,)\n",
    "2. a dataset + other datasets describing features e.g., movie dataset (name, genre, budget, director, etc.) + genre dataset (per genre risk, attendance, rewatchability, etc.) \n",
    "\n",
    "Let's get busy. \n",
    "\n",
    "## More data\n",
    "The easiest case is when you add rows to your table (dataframe) from another table (dataframe). To show this we first create a simple data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>AI</td>\n",
       "      <td>BI</td>\n",
       "      <td>CI</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>AII</td>\n",
       "      <td>BII</td>\n",
       "      <td>CII</td>\n",
       "      <td>DII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III</th>\n",
       "      <td>AIII</td>\n",
       "      <td>BIII</td>\n",
       "      <td>CIII</td>\n",
       "      <td>DIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>AIV</td>\n",
       "      <td>BIV</td>\n",
       "      <td>CIV</td>\n",
       "      <td>DIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A     B     C     D\n",
       "I      AI    BI    CI    DI\n",
       "II    AII   BII   CII   DII\n",
       "III  AIII  BIII  CIII  DIII\n",
       "IV    AIV   BIV   CIV   DIV"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run forest run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_simple_df(columns='ABCD', rows=['I','II','III','IV']):\n",
    "    if isinstance(columns, str):\n",
    "        columns = list(columns)\n",
    "    data = np.empty((len(rows), len(columns)), dtype=object)\n",
    "    for i, r in enumerate(rows):\n",
    "        for j, c in enumerate(columns):\n",
    "            data[i][j] = c+r\n",
    "            \n",
    "    return pd.DataFrame(data, columns=columns, index=rows)\n",
    "\n",
    "# creating a simple dataframe\n",
    "simple_df = create_simple_df()\n",
    "simple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you. \n",
    "1. create a dataframe from rows 0 and 3 of `simple_df`, we'll call it `simple_df_1`\n",
    "2. create a dataframe from rows 2 and 1 of `simple_df`, we'll call it `simple_df_2`\n",
    "3. concatenate the dataframes using `pd.concat`\n",
    "4. concatenate the dataframes using `simple_df_1.append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "I    AI   BI   CI   DI\n",
      "IV  AIV  BIV  CIV  DIV\n",
      "        A     B     C     D\n",
      "III  AIII  BIII  CIII  DIII\n",
      "II    AII   BII   CII   DII\n",
      "        A     B     C     D\n",
      "I      AI    BI    CI    DI\n",
      "IV    AIV   BIV   CIV   DIV\n",
      "III  AIII  BIII  CIII  DIII\n",
      "II    AII   BII   CII   DII\n",
      "        A     B     C     D\n",
      "I      AI    BI    CI    DI\n",
      "IV    AIV   BIV   CIV   DIV\n",
      "III  AIII  BIII  CIII  DIII\n",
      "II    AII   BII   CII   DII\n"
     ]
    }
   ],
   "source": [
    "simple_df_1 = pd.DataFrame(simple_df, columns=['A','B','C','D'], index=['I','IV'])\n",
    "print(simple_df_1)\n",
    "\n",
    "simple_df_2 = pd.DataFrame(simple_df, columns=['A','B','C','D'], index=['III','II'])\n",
    "print(simple_df_2)\n",
    "\n",
    "print(pd.concat([simple_df_1, simple_df_2]))\n",
    "print(simple_df_1.append(simple_df_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes life is not that easy and not all the columns match.\n",
    "1. create a dataframe from rows 0 and 3 and columns 0, 1, 2 of `simple_df`, we'll call it `simple_df_3`\n",
    "2. create a dataframe from rows 2 and 1 and columns 1, 2, 3 of `simple_df`, we'll call it `simple_df_4`\n",
    "3. concatenate the dataframes using `pd.concat`\n",
    "4. concatenate the dataframes using `simple_df_3.append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C\n",
      "I    AI   BI   CI\n",
      "IV  AIV  BIV  CIV\n",
      "        B     C     D\n",
      "III  BIII  CIII  DIII\n",
      "II    BII   CII   DII\n",
      "       A     B     C     D\n",
      "I     AI    BI    CI   NaN\n",
      "IV   AIV   BIV   CIV   NaN\n",
      "III  NaN  BIII  CIII  DIII\n",
      "II   NaN   BII   CII   DII\n",
      "       A     B     C     D\n",
      "I     AI    BI    CI   NaN\n",
      "IV   AIV   BIV   CIV   NaN\n",
      "III  NaN  BIII  CIII  DIII\n",
      "II   NaN   BII   CII   DII\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "simple_df_3 = pd.DataFrame(simple_df, columns=['A','B','C'], index=['I','IV'])\n",
    "print(simple_df_3)\n",
    "\n",
    "simple_df_4 = pd.DataFrame(simple_df, columns=['B','C','D'], index=['III','II'])\n",
    "print(simple_df_4)\n",
    "\n",
    "print(pd.concat([simple_df_3, simple_df_4]))\n",
    "print(simple_df_3.append(simple_df_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is trying, it really is, but you're not making its life easy. With no other option it replaces missing values with NaN. To change `concat` behavior regarding missing values you can give `join` as a keyword argument to `concat`. Repeat the concatenation with `join` set to\n",
    "1. inner\n",
    "2. outer\n",
    "\n",
    "Instead of setting `join` you can decide your only interested in a specific set of columns using the `join_axes` keyword argument to `concat`. Repeat the concatenation with `join_axes` set to `simple_df_4.columns`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        B     C\n",
      "I      BI    CI\n",
      "IV    BIV   CIV\n",
      "III  BIII  CIII\n",
      "II    BII   CII\n",
      "       A     B     C     D\n",
      "I     AI    BI    CI   NaN\n",
      "IV   AIV   BIV   CIV   NaN\n",
      "III  NaN  BIII  CIII  DIII\n",
      "II   NaN   BII   CII   DII\n",
      "        B     C     D\n",
      "I      BI    CI   NaN\n",
      "IV    BIV   CIV   NaN\n",
      "III  BIII  CIII  DIII\n",
      "II    BII   CII   DII\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([simple_df_3, simple_df_4], join='inner', sort=True))\n",
    "print(pd.concat([simple_df_3, simple_df_4], join='outer', sort=True))\n",
    "print(pd.concat([simple_df_3, simple_df_4], join_axes=[simple_df_4.columns], sort=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain in your words what is the difference between the methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your words here*\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching data\n",
    "things get more interesting when we want to enrich each data point (row) with more information. \n",
    "Use `pd.read_csv` to read the following files\n",
    "1. restaurants_details.csv\n",
    "2. restaurants_aux.csv\n",
    "\n",
    "to make sure your data import succeeded print out the head (first few rows) for each dataframe. **YOU SHOULD ALWAYS DO THIS** when importing data as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Restaurant     address     opens_at    closes_at\n",
      "0      humus_hakerem   Shoken 30  08:00:00 AM  07:00:00 PM\n",
      "1         al_harampa  Ha'amal 21  11:00:00 AM  03:00:00 AM\n",
      "2  twenty_four_rupee   Shoken 16  10:00:00 AM  12:00:00 PM\n",
      "3         pizza_much   Shoken 24  11:00:00 AM          NaN\n",
      "4       falafel_gina   Shoken 22  09:00:00 AM  09:00:00 PM\n",
      "          Restaurant     address     type  moogle_rating\n",
      "0      humus_hakerem   Shoken 30    humus            4.1\n",
      "1         al_harampa  Ha'amal 21      pub            4.3\n",
      "2  twenty_four_rupee   Shoken 16   indian            4.3\n",
      "3         pizza_much   Shoken 24    pizza            NaN\n",
      "4       falafel_gina   Shoken 22  falafel            4.0\n"
     ]
    }
   ],
   "source": [
    "det = pd.read_csv('restaurants_details.csv')\n",
    "aux = pd.read_csv('restaurants_aux.csv')\n",
    "print(det.head())\n",
    "print(aux.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.merge` to merge columns of both dataframes and print the result. You can explicitly state on which columns you want to merge using the `on` keyword to merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Restaurant           address     opens_at    closes_at       type  \\\n",
      "0       humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1          al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2   twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3          pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4        falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5               aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6               cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7             vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8               bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9     vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "10            shtern1  avraham shtern 1          NaN          NaN        pub   \n",
      "\n",
      "    moogle_rating  \n",
      "0             4.1  \n",
      "1             4.3  \n",
      "2             4.3  \n",
      "3             NaN  \n",
      "4             4.0  \n",
      "5             3.5  \n",
      "6             3.3  \n",
      "7             4.0  \n",
      "8             4.2  \n",
      "9             4.2  \n",
      "10            NaN  \n"
     ]
    }
   ],
   "source": [
    "det_aux = pd.merge(det,aux)\n",
    "print(det_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want want to join on a column which has a different name in each dataset (table). You can use the `left_on`, `right_on` to specify how the columns to join on is named in both tables.\n",
    "\n",
    "1. Use `pd.read_csv` to read restaurants_data_from_friends.csv\n",
    "2. print out the **entire** dataframe\n",
    "3. us `pd.merge` with the aforementioned keywords to merge this data to our previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  num_of_friends_who_likes  cheapest_lunch\n",
      "0       humus_hakerem                         5              30\n",
      "1          al_harampa                         2              50\n",
      "2   twenty_four_rupee                         3              40\n",
      "3          pizza_much                         0              18\n",
      "4        falafel_gina                         4              25\n",
      "5               aroma                         1              35\n",
      "6               cofix                         2              10\n",
      "7             vitosha                         4              60\n",
      "8               bugsy                         3              55\n",
      "9     vicky_christina                         5              53\n",
      "10              taizu                         1             100\n",
      "          Restaurant           address     opens_at    closes_at       type  \\\n",
      "0      humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1         al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2  twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3         pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4       falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5              aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6              cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7            vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8              bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9    vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "\n",
      "   moogle_rating               Name  num_of_friends_who_likes  cheapest_lunch  \n",
      "0            4.1      humus_hakerem                         5              30  \n",
      "1            4.3         al_harampa                         2              50  \n",
      "2            4.3  twenty_four_rupee                         3              40  \n",
      "3            NaN         pizza_much                         0              18  \n",
      "4            4.0       falafel_gina                         4              25  \n",
      "5            3.5              aroma                         1              35  \n",
      "6            3.3              cofix                         2              10  \n",
      "7            4.0            vitosha                         4              60  \n",
      "8            4.2              bugsy                         3              55  \n",
      "9            4.2    vicky_christina                         5              53  \n"
     ]
    }
   ],
   "source": [
    "friends = pd.read_csv('restaurants_data_from_friends.csv')\n",
    "print(friends)\n",
    "det_aux_friends = pd.merge(det_aux, friends, left_on='Restaurant', right_on='Name')\n",
    "print(det_aux_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this works but we still have the duplicate columns which can be dropped using `<dataframe>.drop`. Try it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>opens_at</th>\n",
       "      <th>closes_at</th>\n",
       "      <th>type</th>\n",
       "      <th>moogle_rating</th>\n",
       "      <th>Name</th>\n",
       "      <th>num_of_friends_who_likes</th>\n",
       "      <th>cheapest_lunch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shoken 30</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>07:00:00 PM</td>\n",
       "      <td>humus</td>\n",
       "      <td>4.1</td>\n",
       "      <td>humus_hakerem</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ha'amal 21</td>\n",
       "      <td>11:00:00 AM</td>\n",
       "      <td>03:00:00 AM</td>\n",
       "      <td>pub</td>\n",
       "      <td>4.3</td>\n",
       "      <td>al_harampa</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shoken 16</td>\n",
       "      <td>10:00:00 AM</td>\n",
       "      <td>12:00:00 PM</td>\n",
       "      <td>indian</td>\n",
       "      <td>4.3</td>\n",
       "      <td>twenty_four_rupee</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shoken 24</td>\n",
       "      <td>11:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pizza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pizza_much</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shoken 22</td>\n",
       "      <td>09:00:00 AM</td>\n",
       "      <td>09:00:00 PM</td>\n",
       "      <td>falafel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>falafel_gina</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>everywhere</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>10:00:00 PM</td>\n",
       "      <td>cafe</td>\n",
       "      <td>3.5</td>\n",
       "      <td>aroma</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>everywhere</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>10:00:00 PM</td>\n",
       "      <td>cafe</td>\n",
       "      <td>3.3</td>\n",
       "      <td>cofix</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yehuda hayamit 3</td>\n",
       "      <td>10:00:00 AM</td>\n",
       "      <td>10:30:00 PM</td>\n",
       "      <td>bulgarian</td>\n",
       "      <td>4.0</td>\n",
       "      <td>vitosha</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shalma road 44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02:00:00 AM</td>\n",
       "      <td>pub</td>\n",
       "      <td>4.2</td>\n",
       "      <td>bugsy</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mitham_hatachana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02:00:00 AM</td>\n",
       "      <td>spanish</td>\n",
       "      <td>4.2</td>\n",
       "      <td>vicky_christina</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            address     opens_at    closes_at       type  moogle_rating  \\\n",
       "0         Shoken 30  08:00:00 AM  07:00:00 PM      humus            4.1   \n",
       "1        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub            4.3   \n",
       "2         Shoken 16  10:00:00 AM  12:00:00 PM     indian            4.3   \n",
       "3         Shoken 24  11:00:00 AM          NaN      pizza            NaN   \n",
       "4         Shoken 22  09:00:00 AM  09:00:00 PM    falafel            4.0   \n",
       "5        everywhere  08:00:00 AM  10:00:00 PM       cafe            3.5   \n",
       "6        everywhere  08:00:00 AM  10:00:00 PM       cafe            3.3   \n",
       "7  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian            4.0   \n",
       "8    shalma road 44          NaN  02:00:00 AM        pub            4.2   \n",
       "9  mitham_hatachana          NaN  02:00:00 AM    spanish            4.2   \n",
       "\n",
       "                Name  num_of_friends_who_likes  cheapest_lunch  \n",
       "0      humus_hakerem                         5              30  \n",
       "1         al_harampa                         2              50  \n",
       "2  twenty_four_rupee                         3              40  \n",
       "3         pizza_much                         0              18  \n",
       "4       falafel_gina                         4              25  \n",
       "5              aroma                         1              35  \n",
       "6              cofix                         2              10  \n",
       "7            vitosha                         4              60  \n",
       "8              bugsy                         3              55  \n",
       "9    vicky_christina                         5              53  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_aux_friends.drop(columns=['Restaurant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing values\n",
    "much like `pd.concat` you can tell pandas what to do regarding missing values using the `how` keyword argument. Aside from `inner` and `outer` you've already seen, you can use `left` or `right` to tell pandas only to keep rows availabe in the left or right dataframe respectively. \n",
    "1. merge using `inner` to keep rows that exist in both dataframes\n",
    "2. merge using `outer` to keep rows that exist in at least one dataframe\n",
    "3. print rows in the outer merge that do not appear in the inner one\n",
    "3. merge using `left` to keep rows that exist in the left dataframe\n",
    "4. merge using `right` to keep rows that exist in the right dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Restaurant           address     opens_at    closes_at       type  \\\n",
      "0      humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1         al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2  twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3         pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4       falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5              aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6              cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7            vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8              bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9    vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "\n",
      "   moogle_rating               Name  num_of_friends_who_likes  cheapest_lunch  \n",
      "0            4.1      humus_hakerem                         5              30  \n",
      "1            4.3         al_harampa                         2              50  \n",
      "2            4.3  twenty_four_rupee                         3              40  \n",
      "3            NaN         pizza_much                         0              18  \n",
      "4            4.0       falafel_gina                         4              25  \n",
      "5            3.5              aroma                         1              35  \n",
      "6            3.3              cofix                         2              10  \n",
      "7            4.0            vitosha                         4              60  \n",
      "8            4.2              bugsy                         3              55  \n",
      "9            4.2    vicky_christina                         5              53  \n",
      "           Restaurant           address     opens_at    closes_at       type  \\\n",
      "0       humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1          al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2   twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3          pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4        falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5               aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6               cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7             vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8               bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9     vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "10            shtern1  avraham shtern 1          NaN          NaN        pub   \n",
      "11                NaN               NaN          NaN          NaN        NaN   \n",
      "\n",
      "    moogle_rating               Name  num_of_friends_who_likes  cheapest_lunch  \n",
      "0             4.1      humus_hakerem                       5.0            30.0  \n",
      "1             4.3         al_harampa                       2.0            50.0  \n",
      "2             4.3  twenty_four_rupee                       3.0            40.0  \n",
      "3             NaN         pizza_much                       0.0            18.0  \n",
      "4             4.0       falafel_gina                       4.0            25.0  \n",
      "5             3.5              aroma                       1.0            35.0  \n",
      "6             3.3              cofix                       2.0            10.0  \n",
      "7             4.0            vitosha                       4.0            60.0  \n",
      "8             4.2              bugsy                       3.0            55.0  \n",
      "9             4.2    vicky_christina                       5.0            53.0  \n",
      "10            NaN                NaN                       NaN             NaN  \n",
      "11            NaN              taizu                       1.0           100.0  \n",
      "           Restaurant           address     opens_at    closes_at       type  \\\n",
      "0       humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1          al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2   twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3          pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4        falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5               aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6               cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7             vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8               bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9     vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "10            shtern1  avraham shtern 1          NaN          NaN        pub   \n",
      "\n",
      "    moogle_rating               Name  num_of_friends_who_likes  cheapest_lunch  \n",
      "0             4.1      humus_hakerem                       5.0            30.0  \n",
      "1             4.3         al_harampa                       2.0            50.0  \n",
      "2             4.3  twenty_four_rupee                       3.0            40.0  \n",
      "3             NaN         pizza_much                       0.0            18.0  \n",
      "4             4.0       falafel_gina                       4.0            25.0  \n",
      "5             3.5              aroma                       1.0            35.0  \n",
      "6             3.3              cofix                       2.0            10.0  \n",
      "7             4.0            vitosha                       4.0            60.0  \n",
      "8             4.2              bugsy                       3.0            55.0  \n",
      "9             4.2    vicky_christina                       5.0            53.0  \n",
      "10            NaN                NaN                       NaN             NaN  \n",
      "           Restaurant           address     opens_at    closes_at       type  \\\n",
      "0       humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM      humus   \n",
      "1          al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM        pub   \n",
      "2   twenty_four_rupee         Shoken 16  10:00:00 AM  12:00:00 PM     indian   \n",
      "3          pizza_much         Shoken 24  11:00:00 AM          NaN      pizza   \n",
      "4        falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM    falafel   \n",
      "5               aroma        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "6               cofix        everywhere  08:00:00 AM  10:00:00 PM       cafe   \n",
      "7             vitosha  yehuda hayamit 3  10:00:00 AM  10:30:00 PM  bulgarian   \n",
      "8               bugsy    shalma road 44          NaN  02:00:00 AM        pub   \n",
      "9     vicky_christina  mitham_hatachana          NaN  02:00:00 AM    spanish   \n",
      "10                NaN               NaN          NaN          NaN        NaN   \n",
      "\n",
      "    moogle_rating               Name  num_of_friends_who_likes  cheapest_lunch  \n",
      "0             4.1      humus_hakerem                         5              30  \n",
      "1             4.3         al_harampa                         2              50  \n",
      "2             4.3  twenty_four_rupee                         3              40  \n",
      "3             NaN         pizza_much                         0              18  \n",
      "4             4.0       falafel_gina                         4              25  \n",
      "5             3.5              aroma                         1              35  \n",
      "6             3.3              cofix                         2              10  \n",
      "7             4.0            vitosha                         4              60  \n",
      "8             4.2              bugsy                         3              55  \n",
      "9             4.2    vicky_christina                         5              53  \n",
      "10            NaN              taizu                         1             100  \n"
     ]
    }
   ],
   "source": [
    "inner_merge = pd.merge(det_aux, friends, left_on='Restaurant', right_on='Name', how='inner')\n",
    "outer_merge = pd.merge(det_aux, friends, left_on='Restaurant', right_on='Name', how='outer')\n",
    "outer_inner_merge = pd.merge(outer_merge, inner_merge, left_on='Name', right_on='Name', how='left')\n",
    "left_merge = pd.merge(det_aux, friends, left_on='Restaurant', right_on='Name', how='left')\n",
    "right_merge = pd.merge(det_aux, friends, left_on='Restaurant', right_on='Name', how='right')\n",
    "print(inner_merge)\n",
    "print(outer_merge)\n",
    "print(left_merge)\n",
    "print(right_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enriching via features\n",
    "sometime you may have data relating to you features that may be useful. \n",
    "1. load restaurants_types_data.csv\n",
    "2. print the dataframe\n",
    "3. merge with out previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      type  sleepy\n",
      "0    humus       5\n",
      "1  falafel       4\n",
      "2     cafe       2\n",
      "3      pub       3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>address</th>\n",
       "      <th>opens_at</th>\n",
       "      <th>closes_at</th>\n",
       "      <th>type</th>\n",
       "      <th>moogle_rating</th>\n",
       "      <th>sleepy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humus_hakerem</td>\n",
       "      <td>Shoken 30</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>07:00:00 PM</td>\n",
       "      <td>humus</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>al_harampa</td>\n",
       "      <td>Ha'amal 21</td>\n",
       "      <td>11:00:00 AM</td>\n",
       "      <td>03:00:00 AM</td>\n",
       "      <td>pub</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bugsy</td>\n",
       "      <td>shalma road 44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02:00:00 AM</td>\n",
       "      <td>pub</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shtern1</td>\n",
       "      <td>avraham shtern 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>falafel_gina</td>\n",
       "      <td>Shoken 22</td>\n",
       "      <td>09:00:00 AM</td>\n",
       "      <td>09:00:00 PM</td>\n",
       "      <td>falafel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aroma</td>\n",
       "      <td>everywhere</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>10:00:00 PM</td>\n",
       "      <td>cafe</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cofix</td>\n",
       "      <td>everywhere</td>\n",
       "      <td>08:00:00 AM</td>\n",
       "      <td>10:00:00 PM</td>\n",
       "      <td>cafe</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant           address     opens_at    closes_at     type  \\\n",
       "0  humus_hakerem         Shoken 30  08:00:00 AM  07:00:00 PM    humus   \n",
       "1     al_harampa        Ha'amal 21  11:00:00 AM  03:00:00 AM      pub   \n",
       "2          bugsy    shalma road 44          NaN  02:00:00 AM      pub   \n",
       "3        shtern1  avraham shtern 1          NaN          NaN      pub   \n",
       "4   falafel_gina         Shoken 22  09:00:00 AM  09:00:00 PM  falafel   \n",
       "5          aroma        everywhere  08:00:00 AM  10:00:00 PM     cafe   \n",
       "6          cofix        everywhere  08:00:00 AM  10:00:00 PM     cafe   \n",
       "\n",
       "   moogle_rating  sleepy  \n",
       "0            4.1       5  \n",
       "1            4.3       3  \n",
       "2            4.2       3  \n",
       "3            NaN       3  \n",
       "4            4.0       4  \n",
       "5            3.5       2  \n",
       "6            3.3       2  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = pd.read_csv('restaurants_type_data.csv')\n",
    "print(types)\n",
    "pd.merge(det_aux, types, how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
