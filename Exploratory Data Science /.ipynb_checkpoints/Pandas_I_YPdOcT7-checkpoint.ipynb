{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "so we all can agree that numpy is great right? But, what if your data looks like this?\n",
    "\n",
    "**name**|**data science training**|**years of experience**|**age**|**years of study**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:\n",
    "jack|no|0|22|12\n",
    "jill|yes|2|25|10\n",
    "tarazan|yes|?|23|11\n",
    "cheetah|yes|1|?|?\n",
    "\n",
    "Trying to handle this data in numpy may be painful:\n",
    "1. each data element (row) has fields which are integers, strings and booleans\n",
    "2. it would be useful to refer to data by name - person name or feature (field) name\n",
    "3. there are multiple missing values\n",
    "\n",
    "Have no fear, Pandas to the rescue. Pandas is a python library specifically designed for data manipulation and analysis. It has answers to all of the previously mentioned issues and much, much more.\n",
    "1. It can pretty much do whatever you can do with a spreadsheet: grouping, pivots, etc.\n",
    "2. It has built-in support for time series\n",
    "3. much, much more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing Pandas\n",
    "make sure you have Pandas installed. Verify it now by trying to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run forest run\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will note that like numpy pandas has a \"canonical\" import statement. Be a pal, use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas objects\n",
    "the two pandas objects anyone should know about are series and dataframes \n",
    "\n",
    "## It's Getting Series - 1D Pandas Objects\n",
    "you can define a pandas series just as you would a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.5\n",
       "2    8.0\n",
       "3    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 1.5, 8, 5])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access data using the familiar numpy syntax. Try generating a slice of `s` containing the first 3 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.5\n",
       "2    8.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not impressed? That's because you didn't see nothing yet. Let's make it more interesting by introducing indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what         0.0\n",
       "about        1.5\n",
       "second       8.0\n",
       "breakfast    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 1.5, 8, 5], index=['what', 'about', 'second', 'breakfast'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can acces data using labels as we would for a dictionary. Try accessing the 'about' field of `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['about']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new found ability does not diminish your ability to slice and dice like the good old numpy days. Try generating a slice `s` containing the first 3 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what      0.0\n",
       "about     1.5\n",
       "second    8.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are like the love child of a numpy array and a dictionary. They can even be generated from a dictionary. Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                        note 7\n",
      "ordinal_number                    7\n",
      "specific_issues    with charging...\n",
      "dtype: object\n",
      "--\n",
      "day        23\n",
      "hour        9\n",
      "month       4\n",
      "year     2018\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "note7 = pd.Series({'model': 'note 7', 'ordinal_number': 7, 'specific_issues': 'with charging...'})\n",
    "print(note7)\n",
    "\n",
    "print('--')\n",
    "\n",
    "disguised_dict = pd.Series(dict(year=2018, month=4, day=23, hour=9))\n",
    "print(disguised_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where it gets wierd, series can also accessed via the dot notation like a class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run forest run\n",
    "disguised_dict.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this merry occasion this may be good time to remind you **NEVER TO USE PANDAS METHODS AS FIELD NAMES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You've been framed, dataframed - 2D Pandas objects and beyond\n",
    "series are nice and all, but 1D data lacks real depth. This is when we turn to dataframes, the real pandas workhorse. Or is that workpanda?... never mind. Let's get busy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(     0    1    2\n",
      "0  1.0  0.0  0.0\n",
      "1  0.0  1.0  0.0\n",
      "2  0.0  0.0  1.0, '\\n')\n",
      "(             a    b    c    d\n",
      "what       1.0  0.0  0.0  0.0\n",
      "about      0.0  1.0  0.0  0.0\n",
      "second     0.0  0.0  1.0  0.0\n",
      "breakfast  0.0  0.0  0.0  1.0, '\\n')\n",
      "(              advanced  simple\n",
      "class_             2.0       1\n",
      "lesson             1.0       2\n",
      "district          13.0       9\n",
      "fudges_given       0.5       0, '\\n')\n",
      "(              advanced  simple\n",
      "class_             2.0       1\n",
      "district          13.0       9\n",
      "fudges_given       0.5       0\n",
      "lesson             1.0       2, '\\n')\n"
     ]
    }
   ],
   "source": [
    "# we can initialize pandas dataframes from a numpy array\n",
    "import numpy as np\n",
    "df = pd.DataFrame(data=np.eye(3))\n",
    "print(df, '\\n')\n",
    "\n",
    "# we can give it indices and labels(columns)\n",
    "df2 = pd.DataFrame(data=np.eye(4), columns=['a', 'b', 'c', 'd'], index=['what', 'about', 'second', 'breakfast'])\n",
    "print(df2, '\\n')\n",
    "\n",
    "# we can compose it a dictionary of series\n",
    "s1 = pd.Series([1, 2, 9, 0], index=['class_', 'lesson', 'district', 'fudges_given'])\n",
    "s2 = pd.Series([2, 1, 13, 0.5], index=['class_', 'lesson', 'district', 'fudges_given'])\n",
    "df3 = pd.DataFrame({'simple': s1, 'advanced': s2})\n",
    "print(df3,'\\n')\n",
    "\n",
    "# or as a dictionary of dictionaries...\n",
    "df4 = pd.DataFrame({\n",
    "    'simple': dict(class_=1, lesson=2, district=9, fudges_given=0),\n",
    "    'advanced': dict(class_=2, lesson=1, district=13, fudges_given=0.5),\n",
    "})\n",
    "print(df4, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing dataframes\n",
    "there are many different and wonderful ways to index dataframes. \n",
    "\n",
    "We can slice dataframes by index as we did for series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         a    b    c    d\n",
      "what   1.0  0.0  0.0  0.0\n",
      "about  0.0  1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but using a single index won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ed40c5c5e83b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run forest run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will soon find out why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what         1.0\n",
      "about        0.0\n",
      "second       0.0\n",
      "breakfast    0.0\n",
      "Name: a, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right. Bracket indexing is reserved for columns (this is confusing). The effect can be repeated using attribute-style (dot) notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what         1.0\n",
      "about        0.0\n",
      "second       0.0\n",
      "breakfast    0.0\n",
      "Name: a, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which does seem more convenient, but does not allow us to assign new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(             a    b    c    d   e\n",
      "what       1.0  0.0  0.0  0.0  90\n",
      "about      0.0  1.0  0.0  0.0  80\n",
      "second     0.0  0.0  1.0  0.0  70\n",
      "breakfast  0.0  0.0  0.0  1.0  60, '\\n')\n",
      "(             a    b    c    d   e\n",
      "what       1.0  0.0  0.0  0.0  90\n",
      "about      0.0  1.0  0.0  0.0  80\n",
      "second     0.0  0.0  1.0  0.0  70\n",
      "breakfast  0.0  0.0  0.0  1.0  60, '\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "df2['e'] = [90, 80, 70, 60]\n",
    "print(df2, '\\n')\n",
    "\n",
    "df2.w = [10, 20, 30, 40]\n",
    "print(df2, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes as 2D arrays\n",
    "beneath all the fancy machinery at the heart of each dataframe lies a numpy array. It's quite easy to find actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0. 90.]\n",
      " [ 0.  1.  0.  0. 80.]\n",
      " [ 0.  0.  1.  0. 70.]\n",
      " [ 0.  0.  0.  1. 60.]]\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this knowledge we can do some clever stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   what  about  second  breakfast\n",
      "a   1.0    0.0     0.0        0.0\n",
      "b   0.0    1.0     0.0        0.0\n",
      "c   0.0    0.0     1.0        0.0\n",
      "d   0.0    0.0     0.0        1.0\n",
      "e  90.0   80.0    70.0       60.0\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print(df2.T)   # transposing as we would for a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing functions - iloc, loc, ix\n",
    "armed with this knowledge of a dataframes inner workings it may be easier to grasp pandas \"advanced\" indexing functions\n",
    "\n",
    "### Pandas what pandas? - iloc\n",
    "if you want to treat dataframes as arrays you came to the right place. The `iloc` function allowes us to index the dataframe as we would a numpy array. Use it now to get the subrarray of `df2` containing rows 0, 1, 2 and columns 3, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          d    b\n",
       "what    0.0  0.0\n",
       "about   0.0  1.0\n",
       "second  0.0  0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[:3,3::-2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutant indexing - loc\n",
    "so you want to slice, but you want to use named ranges. You want it all. Luckily pandas got your back. The `loc` function allows you to slice using names instead of integers. Wrap your head around this one and get the same result you got for `iloc`.\n",
    "\n",
    "*note* - named ranges include both ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a    b    c    d   e\n",
       "what       1.0  0.0  0.0  0.0  90\n",
       "breakfast  0.0  0.0  0.0  1.0  60"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[[True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boolean indexing\n",
    "boolean indexing is possible using the `loc` function by replacing the dimensions by a boolean index. Use the `loc` function to get the sub dataframe of `df2` with columns 'b' and 'c' and rows where the 'a' column is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             b    c\n",
       "about      1.0  0.0\n",
       "second     0.0  1.0\n",
       "breakfast  0.0  0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['a'] == 0, ['b','c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what about numpy??\n",
    "you have not learned numpy for nothing. At their core pandas data frames are simply upgraded numpy arrays, and can be treated as such. Behold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df=\n",
      "    I  II  III  IV\n",
      "a   0   1    2   3\n",
      "b   4   5    6   7\n",
      "c   8   9   10  11\n",
      "d  12  13   14  15\n",
      "\n",
      "mat=\n",
      "[[0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "\n",
      "df.dot(mat)=\n",
      "   0   1   2   3\n",
      "a  0   0   1   2\n",
      "b  0   4   5   6\n",
      "c  0   8   9  10\n",
      "d  0  12  13  14\n",
      "\n",
      "df.dot(mat)=\n",
      "[[ 0  0  1  2]\n",
      " [ 0  4  5  6]\n",
      " [ 0  8  9 10]\n",
      " [ 0 12 13 14]]\n",
      "\n",
      "exponent of df = \n",
      "               I             II           III            IV\n",
      "a       1.000000       2.718282  7.389056e+00  2.008554e+01\n",
      "b      54.598150     148.413159  4.034288e+02  1.096633e+03\n",
      "c    2980.957987    8103.083928  2.202647e+04  5.987414e+04\n",
      "d  162754.791419  442413.392009  1.202604e+06  3.269017e+06\n",
      "\n",
      "df_=\n",
      "    I  II  III  IV      V\n",
      "a   0   1    2   3  silly\n",
      "b   4   5    6   7  words\n",
      "c   8   9   10  11     in\n",
      "d  12  13   14  15   list\n",
      "\n",
      "numeric data in df_ multiplied by mat=\n",
      "   I  II  III  IV\n",
      "a  0   1    0   0\n",
      "b  0   0    6   0\n",
      "c  0   0    0  11\n",
      "d  0   0    0   0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "df = pd.DataFrame(np.arange(16).reshape((4, -1)), index=['a', 'b', 'c', 'd'], columns=['I', 'II', 'III', 'IV'])\n",
    "print('df=\\n{}\\n'.format(df))\n",
    "\n",
    "mat = np.diag(v=[1, 1, 1], k=1)\n",
    "print('mat=\\n{}\\n'.format(mat))\n",
    "\n",
    "print('df.dot(mat)=\\n{}\\n'.format(df.dot(mat))) # implicit example\n",
    "\n",
    "print('df.dot(mat)=\\n{}\\n'.format(df.values.dot(mat))) # explicit example using values\n",
    "\n",
    "print('exponent of df = \\n{}\\n'.format(np.exp(df)))  # calling numpy functions on a pandas dataframe\n",
    "\n",
    "df_ = df.copy()\n",
    "df_['V'] = ['silly', 'words', 'in', 'list']\n",
    "print('df_=\\n{}\\n'.format(df_))\n",
    "print('numeric data in df_ multiplied by mat=\\n{}\\n'.format(df_._get_numeric_data()*mat)) # let's keep it numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can indeed treat pandas dataframes (and series) as numpy objects for most intents and purposes. Pandas, a gracious library and a beautiful creature doesn't mind you treating it as numpy array. It will retain it's column names and indices, for your use and enjoyment (as long as you do it implicitly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exercise\n",
    "Now you. You are requested to get the sub dataframe of with rows 'c' and 'd' and rows 'II', and 'IV' with a transformation applied to each element. If $x$ is the original element we want the element $x'=\\cos(e^{x+3})$. There are two obvious ways to achieve this. Write them both. Which is more efficient?\n",
    "\n",
    "*Note* try to achieve both ways with one line of code each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         II        IV\n",
      "b -0.915744 -0.725042\n",
      "c  0.128037 -0.865213\n",
      "         II        IV\n",
      "b -0.915744 -0.725042\n",
      "c  0.128037 -0.865213\n",
      "\n",
      "The first way is more efficient because we dont need to apply \n",
      "cos(e^x+3) on every element but only to the sub dataframe.\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "xprime = np.cos(np.exp(df.iloc[[1,2],[1,3]]+3))\n",
    "print(xprime)\n",
    "x2prime = np.cos(np.exp(df+3)).iloc[[1,2],[1,3]]\n",
    "print(x2prime)\n",
    "print(\"\\nThe first way is more efficient because we dont need to apply \\ncos(e^x+3) on every element but only to the sub dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "in pandas the row names are called the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'a', u'b', u'c', u'd'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run forest run\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is an immutable list. There are some explicit uses for the index, but it's presented here to discuss the implicit ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index preservation\n",
    "let's compute how busy are the restaurants around the ITC are on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_num=\n",
      "humus_hakerem    100\n",
      "falafel_gina      80\n",
      "24_rupee          60\n",
      "pizza_munch      200\n",
      "dtype: int64\n",
      "\n",
      "hours_open=\n",
      "humus_hakerem    10\n",
      "falafel_gina     12\n",
      "al_harampa        9\n",
      "24_rupee         17\n",
      "dtype: int64\n",
      "\n",
      "average number of customers per hour\n",
      "24_rupee          3.529412\n",
      "al_harampa             NaN\n",
      "falafel_gina      6.666667\n",
      "humus_hakerem    10.000000\n",
      "pizza_munch            NaN\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_num = pd.Series([100, 80, 60, 200],\n",
    "                       index=['humus_hakerem', 'falafel_gina', \n",
    "                              '24_rupee', 'pizza_munch']) # number of customers per day\n",
    "\n",
    "hours_open = pd.Series([10, 12, 9, 17],\n",
    "                      index=['humus_hakerem', 'falafel_gina', \n",
    "                             'al_harampa', '24_rupee'])\n",
    "\n",
    "print('customer_num=\\n{}\\n'.format(customer_num))\n",
    "print('hours_open=\\n{}\\n'.format(hours_open))\n",
    "\n",
    "print('average number of customers per hour\\n{}\\n'.format(customer_num/hours_open))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we perform operations on pandas objects, pandas aligns indices automagically. Elements for which there is no counterpart for computation are replaced by a NaN. This also work for columns and indices in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df=\n",
      "    I  II  III  IV\n",
      "a   0   1    2   3\n",
      "b   4   5    6   7\n",
      "c   8   9   10  11\n",
      "d  12  13   14  15\n",
      "\n",
      "df_nw=\n",
      "   I  II  III\n",
      "a  0   1    2\n",
      "b  4   5    6\n",
      "c  8   9   10\n",
      "\n",
      "df_se=\n",
      "   II  III  IV\n",
      "b   5    6   7\n",
      "c   9   10  11\n",
      "d  13   14  15\n",
      "\n",
      "df_se*df_nw=\n",
      "    I    II    III  IV\n",
      "a NaN   NaN    NaN NaN\n",
      "b NaN  25.0   36.0 NaN\n",
      "c NaN  81.0  100.0 NaN\n",
      "d NaN   NaN    NaN NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print('df=\\n{}\\n'.format(df))\n",
    "\n",
    "df_nw = df.iloc[:3, :3]\n",
    "print('df_nw=\\n{}\\n'.format(df_nw))  # north-west sub dataframe of df\n",
    "\n",
    "df_se = df.iloc[1:, 1:]\n",
    "print('df_se=\\n{}\\n'.format(df_se))  # south-east sub dataframe of df\n",
    "\n",
    "print('df_se*df_nw=\\n{}\\n'.format(df_se*df_nw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could tell in advance which elements would be replaced by NaN's by using logical operations (XOR) on columns and indices.\n",
    "\n",
    "**note** - xor (symbol = ^) is what we call or in every day use. xor stands for exclusive or."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices (rows) that will be replaced with NaNs = Index([u'a', u'd'], dtype='object')\n",
      "\n",
      "columns (columns) that will be replaced with NaNs = Index([u'I', u'IV'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# run forest run\n",
    "print('indices (rows) that will be replaced with NaNs = {}\\n'.format(df_se.index ^ df_nw.index))\n",
    "print('columns (columns) that will be replaced with NaNs = {}'.format(df_se.columns ^ df_nw.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real world cases, missing values are very common and so methods for coping with missing data are baked into pandas. You can use the `dropna` and `fillna` method of a pandas object to drop missing values and fill them respectively.\n",
    "\n",
    "#### exercise\n",
    "create a new dataframe `df_missing` by multiplying `df_se` and `df_nw` to experiment in this exercise (do not alter `df_missing` - print a copy)\n",
    "1. fill missing values with a constant value of your choosing.\n",
    "2. achieve the same result without using `dropna` or `fillna` (hint: `isnull`, `notnull`, `where`)\n",
    "3. drop rows containing NaNs\n",
    "4. drop rows containing **only** NaNs\n",
    "5. achieve the same result without using `dropna` or `fillna`\n",
    "6. drop columns containing **only** NaNs\n",
    "7. achieve the same result without using `dropna` or `fillna`\n",
    "8. fill missing values with the **last** existing value along each row (fill forward)\n",
    "9. fill missing values with the **next** existing value along each column (fill backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    I    II    III  IV\n",
      "a NaN   NaN    NaN NaN\n",
      "b NaN  25.0   36.0 NaN\n",
      "c NaN  81.0  100.0 NaN\n",
      "d NaN   NaN    NaN NaN\n",
      "     I    II    III   IV\n",
      "a  2.0   2.0    2.0  2.0\n",
      "b  2.0  25.0   36.0  2.0\n",
      "c  2.0  81.0  100.0  2.0\n",
      "d  2.0   2.0    2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "df_missing = df_se * df_nw\n",
    "print(df_missing)\n",
    "\n",
    "df_missing2 = df_missing.fillna(2)\n",
    "print(df_missing2)\n",
    "\n",
    "#Nadav aproved me not doing the rest of the excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
